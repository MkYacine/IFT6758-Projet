{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join('..\\data\\datasets\\csv_files','2016-2020-v2.csv')\n",
    "df = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Traitement des valeurs manquantes dans la colonne 'strength':} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_from_strength(df : pd.DataFrame):\n",
    "    for index, row in df.iterrows():\n",
    "    # On cherche les lignes pour lesquelles \n",
    "        if (row['strength'] != 'Even') & (row['strength'] != 'Power Play') & (row['strength'] != 'Short Handed'):\n",
    "            if row['attacking_team_name'] == row['home_team'] :\n",
    "                if row['home_team_players'] < row['away_team_players']:\n",
    "                    df.at[index, 'strength'] = 'Short Handed'\n",
    "                else : \n",
    "                    if row['home_team_players'] == row['away_team_players']:\n",
    "                        df.at[index, 'strength'] = 'Even'\n",
    "                    else :\n",
    "                        df.at[index, 'strength'] = 'Power Play'\n",
    "            else :\n",
    "                if row['away_team_players'] > row['home_team_players']:\n",
    "                    df.at[index, 'strength'] = 'Power Play'\n",
    "                else : \n",
    "                    if row['away_team_players'] == row['home_team_players']:\n",
    "                        df.at[index, 'strength'] = 'Even'\n",
    "                    else : \n",
    "                        df.at[index, 'strength'] = 'Short Handed'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_nan_from_strength(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Encodage des caractéristiques : } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des caractéristiques de type catégorielle :\n",
    "# On utilise LabelEncoder() pour les variables pour lesquelles l'ordre n'est pas important\n",
    "\n",
    "# Colonne pour lesquels l'ordre n'est pas important\n",
    "categorical_columns_1 = ['period_type', 'attacking_team_name', 'shooter', 'goalie', 'rebound', 'last_event_type', 'home_team']\n",
    "\n",
    "# Colonne pour laquelle l'ordre est important\n",
    "# Sachant que certains types de tirs sont plus efficaces en moyenne que d'autre, on encode les \n",
    "# types de tirs les plus efficaces avec des valeurs élevées\n",
    "# (Au Milestone 1, on a vu que les 'Tip-in' sont les plus efficaces et que les 'Wrap-around' sont les moins\n",
    "# efficaces)\n",
    "\n",
    "shot_type_classified = [['Wrap-around',0], ['Slap Shot', 1], ['Snap Shot', 2], ['Wrist Shot', 3], ['Backhand', 4], ['Deflected', 5], ['Tip-In',6]]\n",
    "\n",
    "# La caractéristique 'strength' doit aussi étre encodée de manière ordinale, étant donné\n",
    "# que lorsqu'une équipe est en 'Power Play', elle a plus de chances de marquer tandis que lorsqu'elle est\n",
    "# 'Short handed', ses chances de marquer diminuent\n",
    "strength_classified = [['Short Handed',0], ['Even', 1], ['Power Play', 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df : pd.DataFrame, categorical_features: list, shot_type_classified : list, strength_classified : list):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Encodage des 'shot_type'\n",
    "    mapping_dict = {row[0]: row[1] for row in shot_type_classified}\n",
    "    df['shot_type'] = df['shot_type'].replace(mapping_dict)\n",
    "\n",
    "    # Encodage de 'strength'\n",
    "    mapping_dict_1 = {row[0] : row[1] for row in strength_classified}\n",
    "    df['strength'] = df['strength'].replace(mapping_dict_1)\n",
    "\n",
    "    # Encodage des autres caractéristiques\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for feature in categorical_features :\n",
    "        df[feature] = label_encoder.fit_transform(df[feature]) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = encode_categorical_features(df, categorical_columns_1, shot_type_classified, strength_classified )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Sélection des caractéristiques + Séparation des données (entrainement, validation, test):} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Méthode de filtrage (K-best) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_KBest(X: pd.DataFrame, Y: pd.Series, nb_features: int):\n",
    "\n",
    "    # https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le\n",
    "    selector = SelectKBest(f_classif, k = nb_features)\n",
    "    X_new = pd.DataFrame(selector.fit_transform(X, Y))\n",
    "\n",
    "    names = X.columns.values[selector.get_support()]\n",
    "\n",
    "    return X[names], names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_df(df: pd.DataFrame, test_year : int) :\n",
    "    df = df.copy()\n",
    "    # Ajout d'une colonne pour l'année\n",
    "    df['year'] = df['gameID'].apply(lambda x : x//1000000)\n",
    "\n",
    "    # Récupération du DataFrame de test\n",
    "    test_df = df[df['year'] == test_year]\n",
    "    test_df.drop(columns = 'year')\n",
    "\n",
    "    # Récupération du DataFrame d'entrainement et validation\n",
    "    train_val_df = df[df['year'] == test_year]\n",
    "    train_val_df.drop(columns = 'year')\n",
    "\n",
    "    return test_df, train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des deux DataFrames\n",
    "test_df, train_val_df = get_test_df(df, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanis\\OneDrive\\Bureau\\UdeM\\Science des données\\IFT6758-Projet\\project-env\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [23 27] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\yanis\\OneDrive\\Bureau\\UdeM\\Science des données\\IFT6758-Projet\\project-env\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "X = train_val_df.drop(columns=['is_goal', 'period_time'])\n",
    "Y = train_val_df['is_goal']\n",
    "\n",
    "# On récupère le dataset avec les K-meilleures caractéristiques\n",
    "X_Kbest, Kbest_features = get_features_KBest(X, Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise à jour de notre ensemble de test\n",
    "test_df = test_df[Kbest_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_Kbest, Y, train_size = 0.8, random_state = 42 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Réequilibrage des données : }  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1re approche : Utilisation de SMOTE pour créer des échantillons synthétiques de la classe minoritaire\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_SM = SMOTE(sampling_strategy = 'minority')\n",
    "X_train_over, Y_train_over = oversample_SM.fit_resample(X_train,Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e approche : Utilisation de RandomUnderSampler pour réduire la taille de la classe majoritaire\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_train_res, Y_train_res = rus.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Entrainement d'un modèle RandomForest} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement du modèle sur les données sur-échantillonées par SMOTE\n",
    "RandomForest_model.fit(X_train_over,Y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = RandomForest_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9113,  628],\n",
       "       [ 809,  136]], dtype=int64)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_val,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score : 0.8655249859629421\n",
      "Recall score : 0.17801047120418848\n",
      "F1-score : 0.1591574019894675\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_score :\",accuracy_score(Y_pred, Y_val))\n",
    "print(\"Recall score :\" , recall_score(Y_pred, Y_val))\n",
    "print(\"F1-score :\" , f1_score(Y_pred, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{Méthode de wrapping : Recursive feature elimination (RFE)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR(kernel = 'linear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
